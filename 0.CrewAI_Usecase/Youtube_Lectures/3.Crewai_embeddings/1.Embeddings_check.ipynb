{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55468969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d331ad77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Crew,Task,Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7309ba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install google-generativeai langchain_google_genai -q\n",
    "! pip install -U duckduckgo-search -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d64dd390",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install crewai pypdf langchain sentence-transformers faiss-cpu -q\n",
    "# For GPU support: pip install faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d11612d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohan\\AppData\\Local\\Temp\\ipykernel_16140\\3648100304.py:11: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  self.embeddings = HuggingFaceEmbeddings(\n",
      "c:\\MY_Folder\\MY_Courses\\CrewAI\\crewai_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from crewai import Crew\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "import os\n",
    "\n",
    "class PDFProcessor:\n",
    "    def __init__(self, pdf_path):\n",
    "        self.pdf_path = pdf_path\n",
    "        self.embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "        )\n",
    "    \n",
    "    def load_and_chunk(self):\n",
    "        \"\"\"Load PDF and split into chunks\"\"\"\n",
    "        loader = PyPDFLoader(self.pdf_path)\n",
    "        pages = loader.load()\n",
    "        \n",
    "        # Configure text splitter\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size = 1000,\n",
    "            chunk_overlap = 200,\n",
    "            length_function = len\n",
    "        )\n",
    "        \n",
    "        return text_splitter.split_documents(pages)\n",
    "    \n",
    "    def create_vectorstore(self, chunks, db_name=\"pdf_faiss_db\"):\n",
    "        \"\"\"Create and save FAISS vector store\"\"\"\n",
    "        vectorstore = FAISS.from_documents(\n",
    "            documents = chunks,\n",
    "            embedding  = self.embeddings\n",
    "        )\n",
    "        vectorstore.save_local(db_name)\n",
    "        return vectorstore\n",
    "\n",
    "# Usage\n",
    "processor = PDFProcessor(\"The_GALE_ENCYCLOPEDIA_of_MEDICINE_SECOND.pdf\")\n",
    "chunks = processor.load_and_chunk()\n",
    "vectorstore = processor.create_vectorstore(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6098c4",
   "metadata": {},
   "source": [
    "- Step 3: Integrate with CrewAI Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a326c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for Task\nasync_execution\n  Input should be a valid boolean [type=bool_type, input_value=<function <lambda> at 0x0000029046EB6700>, input_type=function]\n    For further information visit https://errors.pydantic.dev/2.11/v/bool_type",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      4\u001b[39m retriever_agent = Agent(\n\u001b[32m      5\u001b[39m     role=\u001b[33m\"\u001b[39m\u001b[33mInformation Retrieval Specialist\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m     goal=\u001b[33m\"\u001b[39m\u001b[33mFind relevant information from the PDF database\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m     verbose=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     10\u001b[39m )\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Create task that uses the FAISS database\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m research_task = \u001b[43mTask\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mFind relevant information about \u001b[39;49m\u001b[38;5;132;43;01m{topic}\u001b[39;49;00m\u001b[33;43m from our documents\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43magent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretriever_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexpected_output\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mA comprehensive summary of the most relevant information\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Custom function to handle retrieval\u001b[39;49;00m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43masync_execution\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtask_input\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvectorstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43msimilarity_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask_input\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtopic\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Create the crew\u001b[39;00m\n\u001b[32m     22\u001b[39m crew = Crew(\n\u001b[32m     23\u001b[39m     agents=[retriever_agent],\n\u001b[32m     24\u001b[39m     tasks=[research_task],\n\u001b[32m     25\u001b[39m     verbose=\u001b[32m2\u001b[39m\n\u001b[32m     26\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\MY_Folder\\MY_Courses\\CrewAI\\crewai_env\\Lib\\site-packages\\pydantic\\main.py:253\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    252\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    255\u001b[39m     warnings.warn(\n\u001b[32m    256\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    257\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    259\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    260\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for Task\nasync_execution\n  Input should be a valid boolean [type=bool_type, input_value=<function <lambda> at 0x0000029046EB6700>, input_type=function]\n    For further information visit https://errors.pydantic.dev/2.11/v/bool_type"
     ]
    }
   ],
   "source": [
    "from crewai import Agent, Task, Crew\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# 1. First create and save your FAISS vectorstore (as shown in previous examples)\n",
    "# Assume vectorstore is already created and loaded\n",
    "\n",
    "# 2. Create a retrieval tool/function\n",
    "def retrieve_from_faiss(topic: str, k: int = 4):\n",
    "    \"\"\"Custom retrieval function for FAISS\"\"\"\n",
    "    return vectorstore.similarity_search(topic, k=k)\n",
    "\n",
    "# 3. Create the agent with custom tools\n",
    "retriever_agent = Agent(\n",
    "    role=\"Information Retrieval Specialist\",\n",
    "    goal=\"Find relevant information from the PDF database\",\n",
    "    backstory=\"Expert in semantic search and information retrieval\",\n",
    "    tools=[],  # We'll add our custom retrieval function to the task\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 4. Create task with proper configuration\n",
    "research_task = Task(\n",
    "    description=\"Find relevant information about {topic} from our documents\",\n",
    "    agent=retriever_agent,\n",
    "    expected_output=\"A comprehensive summary of the most relevant information\",\n",
    "    # Remove async_execution or set it to True/False only\n",
    "    async_execution=False,  # This must be boolean\n",
    "    # Use context parameter to pass our retrieval function\n",
    "    context=[\n",
    "        {\n",
    "            \"function\": retrieve_from_faiss,\n",
    "            \"description\": \"Retrieves relevant document chunks about a topic\",\n",
    "            \"arguments\": [\"topic\"]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 5. Create and run the crew\n",
    "crew = Crew(\n",
    "    agents=[retriever_agent],\n",
    "    tasks=[research_task],\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Execute with a query\n",
    "result = crew.kickoff(inputs={\"topic\": \"machine learning\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bb67c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew\n",
    "\n",
    "# 1. Define retrieval function\n",
    "def retrieve_docs(topic: str):\n",
    "    results = vectorstore.similarity_search(topic, k=4)\n",
    "    return results\n",
    "\n",
    "# 2. Create agent\n",
    "retriever_agent = Agent(\n",
    "    role=\"Information Retrieval Specialist\",\n",
    "    goal=\"Find relevant information from the PDF database\",\n",
    "    backstory=\"Expert in semantic search and information retrieval\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 3. Create task with context\n",
    "research_task = Task(\n",
    "    description=\"Find relevant information about {topic} from our documents\",\n",
    "    agent=retriever_agent,\n",
    "    expected_output=\"A comprehensive summary of the most relevant information\",\n",
    "    context=[{\n",
    "        \"source\": retrieve_docs,\n",
    "        \"description\": \"FAISS document retriever\",\n",
    "        \"arguments\": [\"topic\"]\n",
    "    }]\n",
    ")\n",
    "\n",
    "# 4. Create and run crew\n",
    "crew = Crew(\n",
    "    agents=[retriever_agent],\n",
    "    tasks=[research_task],\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "result = crew.kickoff(inputs={\"topic\": \"machine learning\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe104a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew\n",
    "from crewai_tools import tool\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# 1. Create a tool for FAISS retrieval\n",
    "@tool(\"FAISS Document Retriever\")\n",
    "def faiss_retriever(topic: str) -> str:\n",
    "    \"\"\"Retrieves relevant document chunks about a topic from FAISS database\"\"\"\n",
    "    results = vectorstore.similarity_search(topic, k=4)\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in results])\n",
    "\n",
    "# 2. Create agent with the tool\n",
    "retriever_agent = Agent(\n",
    "    role=\"Information Retrieval Specialist\",\n",
    "    goal=\"Find relevant information from the PDF database\",\n",
    "    backstory=\"Expert in semantic search and information retrieval\",\n",
    "    tools=[faiss_retriever],  # Add our FAISS tool\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 3. Create task (no async_execution needed for this approach)\n",
    "research_task = Task(\n",
    "    description=\"Find relevant information about {topic} from our documents\",\n",
    "    agent=retriever_agent,\n",
    "    expected_output=\"A comprehensive summary of the most relevant information\",\n",
    "    # async_execution=False,  # Optional, defaults to False\n",
    ")\n",
    "\n",
    "# 4. Create and run crew\n",
    "crew = Crew(\n",
    "    agents=[retriever_agent],\n",
    "    tasks=[research_task],\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "result = crew.kickoff(inputs={\"topic\": \"machine learning\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f662de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crewai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
